{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Manipulate the file system\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Copy dictionaries\n",
    "import copy\n",
    "\n",
    "# Regular expressions\n",
    "import re\n",
    "\n",
    "# Display errors in realtime\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# work with dates\n",
    "import datetime\n",
    "import arrow\n",
    "import time\n",
    "\n",
    "# For scrubbing PII\n",
    "import hashlib\n",
    "\n",
    "# Convert stored string representation of a list to a list\n",
    "import ast\n",
    "\n",
    "# Recurse through a directory tree and return file names with glob\n",
    "import glob\n",
    "\n",
    "# Decode and re-encode mangled Arabic file names\n",
    "import codecs\n",
    "\n",
    "# Connect to a SQLite database in a lazy manner.\n",
    "import sqlalchemy\n",
    "import dataset\n",
    "\n",
    "# Enables opening and reading of Excel files\n",
    "import openpyxl\n",
    "\n",
    "# Import Pandas for easy importing of an excel file\n",
    "import csv\n",
    "\n",
    "# Translating variables, sheet names, and workbook names from Arabic\n",
    "# This is NOT free to use.\n",
    "from google.cloud import translate\n",
    "\n",
    "# Set the environment variable for the Google Service Account\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = 'C:\\\\Users\\\\clay\\\\Documents\\\\fxb-lcs-2b24f4f8a73a.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created database from template: sams_data_phase11.sqlite\n"
     ]
    }
   ],
   "source": [
    "#If there's an existing db for this sheet, delete it\n",
    "#so that we can copy from the template for a fresh start\n",
    "\n",
    "try:\n",
    "    os.remove(\"sams_data_phase11.sqlite\")\n",
    "    print(\"Removed template clone sams_data_phase11.sqlite\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    # Try to preserve a copy in case there is a problem and it has to be restored\n",
    "    shutil.copy2(\"sams_data_phase11_template.sqlite\",\"sams_data_phase11.sqlite\")\n",
    "    \n",
    "    print(\"Created database from template: sams_data_phase11.sqlite\")\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is redundant and the following one will also be redundant. I did that to maintain an execution order that mimics the order in which I processed the data. The problem is that the list of facilities originally provided by SAMS was lacking several, which led to the inability to map facilities to files. \n",
    "\n",
    "Some of those facilities are imported here. Given that they are lacking dates for open and close, I stubbed in 6/15/2017 and hope that we get better data in coming days. Upon receiving further updates, the best process will be to update the additional_facilities.csv file and then rerun this and subsequent notebooks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "additional_facilities_file = \"additional_facilities_08-NOV-2017.csv\"\n",
    "\n",
    "# This includes only two columns: id and facility_id. The id column is the id in the files table.\n",
    "updated_files_file = \"updated_files_08-NOV-2017.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_facilities = []\n",
    "\n",
    "with open(additional_facilities_file,'r',encoding='utf-8-sig') as csvfile:\n",
    "    csvreader = csv.reader(csvfile)\n",
    "    header = next(csvreader)\n",
    "    # header = [\"_\".join(e.lower().strip().split()) for e in header]\n",
    "    for row in csvreader:\n",
    "        rowdict = dict(zip(header,row))\n",
    "        \n",
    "        # Convert empty strings to null values\n",
    "        for k in rowdict.keys():\n",
    "            if rowdict[k].strip() == '':\n",
    "                rowdict[k] = None\n",
    "                \n",
    "        data_facilities.append(rowdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "db = dataset.connect(\"sqlite:///sams_data_phase11.sqlite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tab_facilities = db['facilities']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for rec in data_facilities:\n",
    "    tab_facilities.insert(rec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now code those facilities based on the locations table. Code from file 09."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tab_locations = db['locations']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "location_lookup = {\n",
    "    \"country\":{},\n",
    "    \"governorate\":{},\n",
    "    \"district\":{},\n",
    "    \"subdistrict\":{}\n",
    "}\n",
    "locs = [l for l in tab_locations.find()]\n",
    "\n",
    "for loc in locs:\n",
    "    location_lookup[loc['level']][loc['location_name']] = loc['id']\n",
    "    \n",
    "updated_facilities = []\n",
    "    \n",
    "for rec in tab_facilities.find():\n",
    "    country = rec['country']\n",
    "    governorate = rec['governorate']\n",
    "    district = rec['district']\n",
    "    subdistrict = rec['subdistrict']\n",
    "    rec[\"country_id\"] = location_lookup[\"country\"][country]\n",
    "    rec[\"governorate_id\"] = location_lookup[\"governorate\"][governorate]\n",
    "    rec[\"district_id\"] = location_lookup[\"district\"][district]\n",
    "    rec[\"subdistrict_id\"] = location_lookup[\"subdistrict\"][subdistrict]\n",
    "    rec[\"aleppo\"] = 0\n",
    "    if governorate == \"Aleppo\":\n",
    "        rec[\"aleppo\"] = 1\n",
    "    \n",
    "    updated_facilities.append(rec)\n",
    "    \n",
    "for rec in updated_facilities:\n",
    "    tab_facilities.update(rec,['id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace the `facility_id` values in the `file` table with the updated data from Ranya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_files = []\n",
    "\n",
    "with open(updated_files_file,'r',encoding='utf-8-sig') as csvfile:\n",
    "    csvreader = csv.reader(csvfile)\n",
    "    header = next(csvreader)\n",
    "    for row in csvreader:\n",
    "        rowdict = dict(zip(header,row))\n",
    "        \n",
    "        # Convert empty strings to null values\n",
    "        for k in rowdict.keys():\n",
    "            if rowdict[k].strip() == '':\n",
    "                rowdict[k] = None\n",
    "                \n",
    "        data_files.append(rowdict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update the records in the `files` table to include the updated `facility_id` values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tab_files = db['files']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for rec in data_files:\n",
    "    tab_files.update(rec,['id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In `files`, all `facility_id` instances equal to 70 need to be set to 309 instead. The type of `310` needs to be set to Hospital."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "update_files = []\n",
    "\n",
    "for rec in tab_files.find():\n",
    "    if rec['facility_id'] == 70:\n",
    "        rec['facility_id'] = 309\n",
    "        update_files.append(rec)\n",
    "        \n",
    "for update in update_files:\n",
    "    tab_files.update(update,['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the type of 310 to Hospital\n",
    "\n",
    "row = tab_facilities.find_one(id=310)\n",
    "row['facility_type'] = \"Hospital\"\n",
    "tab_facilities.update(row,['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Delete the duplicate facility\n",
    "tab_facilities.delete(id=70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recreate the facilities_timeline table. Mosty copy of code from notebook 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 2017\n"
     ]
    }
   ],
   "source": [
    "ongoing_date = arrow.get('2017-06-30','YYYY-MM-DD')\n",
    "\n",
    "ongoing_date_month = int(ongoing_date.format(\"MM\"))\n",
    "ongoing_date_year  = int(ongoing_date.format(\"YYYY\"))\n",
    "\n",
    "print(ongoing_date_month,ongoing_date_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def records_for_range(open_date,close_date,facility_id):\n",
    "    \"\"\"\n",
    "    Given two dates that form a range, return records\n",
    "    for insertion in the database that span the date\n",
    "    range.\n",
    "    \"\"\"\n",
    "    records = []\n",
    "    active_date = arrow.get(open_date.ceil('month').date())\n",
    "    close_date = arrow.get(close_date.ceil('month').date())\n",
    "    \n",
    "    while active_date <= close_date:\n",
    "        active_year = int(active_date.format(\"YYYY\"))\n",
    "        active_month = int(active_date.format(\"MM\"))\n",
    "        rec = {\"facility_id\":facility_id, \"year\":active_year,\"month\":active_month}\n",
    "        records.append(rec)\n",
    "        active_date = active_date.shift(months=+1)\n",
    "        \n",
    "    return records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_timeline_from_facility(facility_record):\n",
    "    open1 = facility_record['dateopened']\n",
    "    close1 = facility_record['dateclosed']\n",
    "    open2 = facility_record['reopened1']\n",
    "    close2 = facility_record['closed1']\n",
    "    open3 = facility_record['reopened2']\n",
    "    close3 = facility_record['closed2']\n",
    "    \n",
    "    openstatus = facility_record['openstatus']\n",
    "    \n",
    "    facility_id = facility_record['id']\n",
    "    \n",
    "    # There are no dates and the facility is closed\n",
    "    if not open1 and openstatus == \"0\":\n",
    "        return []\n",
    "    \n",
    "    facility_records = []\n",
    "    \n",
    "    if open1:\n",
    "        # Case: facility has an open1 date\n",
    "        open1 = arrow.get(open1,\"YYYY-MM-DD\")\n",
    "        \n",
    "        # Find the close date\n",
    "        if close1 == \"ongoing\" or close1 is None:\n",
    "            # Case: facility is still open\n",
    "            facility_records = records_for_range(open1,ongoing_date,facility_id)\n",
    "        else:\n",
    "            close1 = arrow.get(close1,\"YYYY-MM-DD\")\n",
    "            facility_records = records_for_range(open1,close1,facility_id)\n",
    "            \n",
    "    else:\n",
    "        if openstatus == \"1\":\n",
    "            # Case: facility has no dates but openstatus is 1\n",
    "            \n",
    "            rec = {\"facility_id\":facility_id,\"year\":ongoing_date_year,\"month\":ongoing_date_month}\n",
    "            facility_records.append(rec)\n",
    "            return facility_records\n",
    "        else:\n",
    "            # Case: facility has no dates but and openstatus is 0\n",
    "            return []\n",
    "        \n",
    "    # TODO: Check that open2 is not ongoing\n",
    "    if open2:\n",
    "        open2 = arrow.get(open2,\"YYYY-MM-DD\")\n",
    "        \n",
    "        if close2 == \"ongoing\" or close2 is None:\n",
    "            facility_records += records_for_range(open2,ongoing_date,facility_id)\n",
    "        else:\n",
    "            close2 = arrow.get(close2,\"YYYY-MM-DD\")\n",
    "            facility_records += records_for_range(open2,close2,facility_id)\n",
    "            \n",
    "    if open3:\n",
    "        open3 = arrow.get(open3,\"YYYY-MM-DD\")\n",
    "        \n",
    "        if close3 == \"ongoing\" or close3 is None:\n",
    "            facility_records += records_for_range(open3,ongoing_date,facility_id)\n",
    "        else:\n",
    "            close3 = arrow.get(close3,\"YYYY-MM-DD\")\n",
    "            facility_records += records_for_range(open3,close3,facility_id)\n",
    "            \n",
    "    return facility_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "facilities = [x for x in tab_facilities.find()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get all the records that need to be put into the timeline table. \n",
    "all_facility_recs = []\n",
    "for f in facilities:\n",
    "    all_facility_recs += extract_timeline_from_facility(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    tab_timeline.drop()\n",
    "except:\n",
    "    pass\n",
    "\n",
    "tab_timeline = db['facility_timeline']\n",
    "\n",
    "tab_timeline.insert_many(all_facility_recs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1928635 records in the full_raw_scrubbed table, without filtering.\n",
    "\n",
    "```\n",
    "SELECT COUNT(*) FROM full_raw_scrubbed\n",
    "WHERE a_file_id IN (\n",
    "\tSELECT files.id\n",
    "\tFROM files \n",
    "\tJOIN facilities\n",
    "\tON files.facility_id = facilities.id\n",
    "\tWHERE facilities.aleppo = 1\n",
    ");\n",
    "```\n",
    "\n",
    "23470 records in the full_raw_scrubbed table when filtering to Aleppo facilities.\n",
    "\n",
    "Create `aleppo_arabic_values` table. Code from notebook 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tab_raw = db['full_raw_scrubbed']\n",
    "tab_arabic = db['aleppo_arabic_values']\n",
    "tab_vars = db['variables']\n",
    "\n",
    "column_names = db.query(\"SELECT DISTINCT(normalized) FROM variables;\")\n",
    "column_names = sorted([r['normalized'] for r in column_names])\n",
    "\n",
    "# We don't want to work with the values in the fields that have been hashed,\n",
    "# so remove them from the list of variables to query.\n",
    "fields = [\n",
    "    \"info_name\",\n",
    "    \"info_name_author\",\n",
    "    \"info_name_caregiver\",\n",
    "    \"info_name_facility\",\n",
    "    \"info_name_group\",\n",
    "    \"info_name_of_coach\",\n",
    "    \"info_name_processor\",\n",
    "    \"info_name_surgeon\",\n",
    "    \"info_phone_skype\",\n",
    "    \"date\",\n",
    "    \"date_first_exam\",\n",
    "    \"death_date\"\n",
    "]\n",
    "column_names = [e for e in column_names if e not in fields]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Iterate through the column names, get the distinct values, check\n",
    "# if they can be cast to floats. If  not, then translate them\n",
    "# The brackets are needed in the SQL query because some of the column\n",
    "# names are the same as SQL reserved words. The brackets tell the database\n",
    "# to look for a column with that name instead of interpreting it as\n",
    "# the reserved word. 'case' is an example here.\n",
    "\n",
    "\n",
    "tab_arabic.delete()\n",
    "    \n",
    "for col in column_names:\n",
    "    col_values = db.query(\"\"\"\n",
    "        SELECT DISTINCT([\"\"\" + col + \"\"\"]) \n",
    "        FROM full_raw_scrubbed \n",
    "        WHERE [\"\"\" + col + \"\"\"] IS NOT NULL\n",
    "        AND [\"\"\" + col + \"\"\"] <> '.'\n",
    "        AND [\"\"\" + col + \"\"\"] <> ''\n",
    "        AND a_file_id IN (\n",
    "            SELECT files.id\n",
    "            FROM files \n",
    "            JOIN facilities\n",
    "            ON files.facility_id = facilities.id\n",
    "            WHERE facilities.aleppo = 1\n",
    "        );\n",
    "        \"\"\")\n",
    "    col_values = [r[col] for r in col_values]\n",
    "\n",
    "    # Create a table of unique Arabic values\n",
    "    for v in col_values:\n",
    "        # Skip numbers\n",
    "        if v.replace(\",\",\".\").replace('.','',1).isdigit():\n",
    "            continue\n",
    "        else:\n",
    "            r = {\"arabic\":v,\"google_translate\":None,\"human_translate\":None,\"normalized\":None}\n",
    "            tab_arabic.upsert(r,['arabic'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update the `aleppo_arabic_values` table so that we know which columns the values appear in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the references\n",
    "\n",
    "arabic_reference = {}\n",
    "\n",
    "for row in tab_arabic.find():\n",
    "    arabic_reference[row['arabic']] = {'id':row['id'],'cols':set()}\n",
    "    \n",
    "# This takes a while to run\n",
    "\n",
    "for col in column_names:\n",
    "    col_values = db.query(\"\"\"\n",
    "        SELECT DISTINCT([\"\"\" + col + \"\"\"]) \n",
    "        FROM full_raw_scrubbed \n",
    "        WHERE [\"\"\" + col + \"\"\"] IS NOT NULL\n",
    "        AND [\"\"\" + col + \"\"\"] <> '.'\n",
    "        AND [\"\"\" + col + \"\"\"] <> ''\n",
    "        AND a_file_id IN (\n",
    "            SELECT files.id\n",
    "            FROM files \n",
    "            JOIN facilities\n",
    "            ON files.facility_id = facilities.id\n",
    "            WHERE facilities.aleppo = 1\n",
    "        );\n",
    "        \"\"\")\n",
    "    col_values = [r[col] for r in col_values]\n",
    "    \n",
    "    # For each value in a given column, make sure our reference dict\n",
    "    # knows that the arabic_values row is referenced by that column\n",
    "    for arabic_value in col_values:\n",
    "        try:\n",
    "            arabic_reference[arabic_value]['cols'].add(col)\n",
    "        except:\n",
    "            # KeyError means we removed the value from arabic_values because\n",
    "            # it was not Arabic and did not require translation to English\n",
    "            pass\n",
    "        \n",
    "# Now take the data we have about which columns contain the relevant\n",
    "# values and upsert it into the arabic_values table\n",
    "\n",
    "for row_arabic in arabic_reference.keys():\n",
    "    row_data = arabic_reference[row_arabic]\n",
    "    data = {'id':row_data['id'],'appears_in':str(sorted(list(row_data['cols'])))}\n",
    "    tab_arabic.upsert(data,['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a lookup for the full set of Arabic Values\n",
    "\n",
    "tab_arabic_orig = db['arabic_values']\n",
    "\n",
    "ar_lookup = {r['arabic']:{\"google\":r['google_translate'],\"human\":r['human_translate']} for r in tab_arabic_orig.find()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aleppo_updates = []\n",
    "for row in tab_arabic.find():\n",
    "    update_row = {\"id\":row['id']}\n",
    "    try:\n",
    "        update_row['google_translate'] = ar_lookup[row['arabic']]['google']\n",
    "        update_row['human_translate'] = ar_lookup[row['arabic']]['human']\n",
    "        aleppo_updates.append(update_row)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "for row in aleppo_updates:\n",
    "    tab_arabic.update(row,['id'])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There appear to be some newline characters in the table, so remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aleppo_updates = []\n",
    "\n",
    "for row in tab_arabic.find():\n",
    "    if row['human_translate']:\n",
    "        row['human_translate'] = row['human_translate'].replace(\"\\n\",\" \").replace(\"\\t\",\" \").strip()\n",
    "    \n",
    "    if row['google_translate']:\n",
    "        row['google_translate'] = row['google_translate'].replace(\"\\n\",\" \").replace(\"\\t\",\" \").strip()\n",
    "    \n",
    "    if row['arabic']:\n",
    "        row['arabic'] = row['arabic'].replace(\"\\n\",\" \").replace(\"\\t\",\" \").strip()\n",
    "    \n",
    "    aleppo_updates.append(row)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for row in aleppo_updates:\n",
    "    tab_arabic.update(row,['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sams_data_phase12_template.sqlite'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Copy the database over as the template for the next file.\n",
    "\n",
    "# Do not rerun this cell!\n",
    "shutil.copy2('sams_data_phase11.sqlite','sams_data_phase12_template.sqlite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
