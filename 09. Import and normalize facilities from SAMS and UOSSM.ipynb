{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Manipulate the file system\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Copy dictionaries\n",
    "import copy\n",
    "\n",
    "# Regular expressions\n",
    "import re\n",
    "\n",
    "# Display errors in realtime\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# work with dates\n",
    "import datetime\n",
    "import arrow\n",
    "import time\n",
    "\n",
    "# For scrubbing PII\n",
    "import hashlib\n",
    "\n",
    "# Convert stored string representation of a list to a list\n",
    "import ast\n",
    "\n",
    "# Recurse through a directory tree and return file names with glob\n",
    "import glob\n",
    "\n",
    "# Decode and re-encode mangled Arabic file names\n",
    "import codecs\n",
    "\n",
    "# Connect to a SQLite database in a lazy manner.\n",
    "import sqlalchemy\n",
    "import dataset\n",
    "\n",
    "# Enables opening and reading of Excel files\n",
    "import openpyxl\n",
    "\n",
    "# Import Pandas for easy importing of an excel file\n",
    "import csv\n",
    "\n",
    "# Translating variables, sheet names, and workbook names from Arabic\n",
    "# This is NOT free to use.\n",
    "from google.cloud import translate\n",
    "\n",
    "# Set the environment variable for the Google Service Account\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = 'C:\\\\Users\\\\clay\\\\Documents\\\\fxb-lcs-2b24f4f8a73a.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed template clone sams_data_phase09.sqlite\n",
      "Created database from template: sams_data_phase09.sqlite\n"
     ]
    }
   ],
   "source": [
    "#If there's an existing db for this sheet, delete it\n",
    "#so that we can copy from the template for a fresh start\n",
    "\n",
    "try:\n",
    "    os.remove(\"sams_data_phase09.sqlite\")\n",
    "    print(\"Removed template clone sams_data_phase09.sqlite\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    # Try to preserve a copy in case there is a problem and it has to be restored\n",
    "    shutil.copy2(\"sams_data_phase09_template.sqlite\",\"sams_data_phase09.sqlite\")\n",
    "    \n",
    "    print(\"Created database from template: sams_data_phase09.sqlite\")\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "db = dataset.connect(\"sqlite:///sams_data_phase09.sqlite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Files with the facilities data to reconcile\n",
    "path_uossm = \"facilities_uossm.csv\"\n",
    "path_sams = \"facilities_sams.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the facilities data from both files, reconcile it in memory, then create the appropriate tables in the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_from_csv(csvfile,org_name):\n",
    "    \"\"\"\n",
    "    Clean the incoming facility data and structure it for push into database\n",
    "    \"\"\"\n",
    "    data_holder = []\n",
    "    csvreader = csv.reader(csvfile)\n",
    "    header = next(csvreader)\n",
    "    header = [\"_\".join(e.lower().strip().split()) for e in header]\n",
    "    for row in csvreader:\n",
    "        #row_fixed = [e.lower().strip() for e in row]\n",
    "        rowdict = dict(zip(header,row))\n",
    "        # Convert empty strings to null values\n",
    "        for k in rowdict.keys():\n",
    "            if rowdict[k].strip() == '':\n",
    "                rowdict[k] = None\n",
    "                \n",
    "        # Try to convert dates to the standard format of YYYY-MM-DD\n",
    "        for k in rowdict.keys():\n",
    "            if ('open' in k or 'close' in k or 'date' in k) and rowdict[k] and 'status' not in k and rowdict[k] != 'ongoing':\n",
    "                try:\n",
    "                    d = arrow.get(rowdict[k],'D/M/YYYY').format(\"YYYY-MM-DD\")\n",
    "                    rowdict[k] = d\n",
    "                except:\n",
    "                    pass\n",
    "        \n",
    "        rowdict['organization'] = org_name\n",
    "        data_holder.append(rowdict)\n",
    "    return data_holder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the SAMS facility data\n",
    "data_sams = []\n",
    "\n",
    "with open(path_sams,'r',encoding='utf-8') as csvfile:\n",
    "    data_sams = extract_from_csv(csvfile,\"SAMS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the UOSSM facility data\n",
    "data_uossm = []\n",
    "\n",
    "with open(path_uossm,'r',encoding='utf-8') as csvfile:\n",
    "    data_uossm = extract_from_csv(csvfile,\"UOSSM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Combine the data sources\n",
    "data = data_sams + data_uossm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since I'm unaware of how we may shift our geo tracking of these facilities, I'm creating a simple self-referencing locations table to create a graph of locations.\n",
    "\n",
    "Currently have: `country -> governorate -> district -> subdistrict`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab_locations = db['locations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This could be done more efficiently, but I'm being verbose due to lack of time\n",
    "countries = set([r['country'] for r in data])\n",
    "countries = [{\"location_name\":c,\"level\":\"country\",\"parent_id\":None} for c in countries]\n",
    "\n",
    "governorates = set([r['governorate'] for r in data])\n",
    "governorates = [{\"location_name\":c,\"level\":\"governorate\",\"parent_id\":None} for c in governorates]\n",
    "\n",
    "districts = set([r['district'] for r in data])\n",
    "districts = [{\"location_name\":c,\"level\":\"district\",\"parent_id\":None} for c in districts]\n",
    "\n",
    "subdistricts = set([r['subdistrict'] for r in data])\n",
    "subdistricts = [{\"location_name\":c,\"level\":\"subdistrict\",\"parent_id\":None} for c in subdistricts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab_locations.insert_many(countries)\n",
    "tab_locations.insert_many(governorates)\n",
    "tab_locations.insert_many(districts)\n",
    "tab_locations.insert_many(subdistricts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_lookup = {\n",
    "    \"country\":{},\n",
    "    \"governorate\":{},\n",
    "    \"district\":{},\n",
    "    \"subdistrict\":{}\n",
    "}\n",
    "locs = [l for l in tab_locations.find()]\n",
    "\n",
    "for loc in locs:\n",
    "    location_lookup[loc['level']][loc['location_name']] = loc['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actual locations in tuple-graphs\n",
    "locations = set((d['country'],d['governorate'],d['district'],d['subdistrict']) for d in data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a reflection of the locations but using their ID numbers.\n",
    "locations_ids = []\n",
    "for l in locations:\n",
    "    country_id = location_lookup[\"country\"][l[0]]\n",
    "    governorate_id = location_lookup[\"governorate\"][l[1]]\n",
    "    district_id = location_lookup[\"district\"][l[2]]\n",
    "    subdistrict_id = location_lookup[\"subdistrict\"][l[3]]\n",
    "    rec = [country_id,governorate_id,district_id,subdistrict_id]\n",
    "    locations_ids.append(rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now update the locations table for the parenting\n",
    "for place in locations_ids:\n",
    "    for index in range(3,0,-1):\n",
    "        loc_rec_to_update = dict(id=place[index],parent_id=place[index-1])\n",
    "        tab_locations.update(loc_rec_to_update,['id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the locations are in the table, we need to create a facilities table and map the locations to the facilities. The tracking of the open/closed status of the facilities needs to eventually be broken out in a more robust manner, but for now, to expedite translation work, the facilities list will be used to reduce the raw file data and export a minified Arabic Values table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for rec in data:\n",
    "    country = rec['country']\n",
    "    governorate = rec['governorate']\n",
    "    district = rec['district']\n",
    "    subdistrict = rec['subdistrict']\n",
    "    rec[\"country_id\"] = location_lookup[\"country\"][country]\n",
    "    rec[\"governorate_id\"] = location_lookup[\"governorate\"][governorate]\n",
    "    rec[\"district_id\"] = location_lookup[\"district\"][district]\n",
    "    rec[\"subdistrict_id\"] = location_lookup[\"subdistrict\"][subdistrict]\n",
    "    rec[\"aleppo\"] = 0\n",
    "    if governorate == \"Aleppo\":\n",
    "        rec[\"aleppo\"] = 1\n",
    "        \n",
    "    # Deduplication of facilities will happen through parenting\n",
    "    rec[\"facility_parent_id\"] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert the records into a facilities table\n",
    "try:\n",
    "    tab_facilities.drop()\n",
    "except:\n",
    "    pass\n",
    "\n",
    "tab_facilities = db['facilities']\n",
    "\n",
    "for rec in data:\n",
    "    tab_facilities.insert(rec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading in a file to help assign facilities to files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'file_name', 'ungarbled', 'translation', 'facility_id', 'possible_problem', 'file_path']\n"
     ]
    }
   ],
   "source": [
    "f = \"facilities_tagged.csv\"\n",
    "\n",
    "tagged = []\n",
    "\n",
    "with open(f,'r',encoding='utf-8-sig') as csvfile:\n",
    "    csvreader = csv.reader(csvfile)\n",
    "    header = next(csvreader)\n",
    "    print(header)\n",
    "    for row in csvreader:\n",
    "        #row_fixed = [e.lower().strip() for e in row]\n",
    "        rowdict = dict(zip(header,row))\n",
    "        if rowdict['facility_id'] == '':\n",
    "            rowdict['facility_id'] = None\n",
    "        rowdict['path_parts'] = rowdict['file_path'].split(\"\\\\\")\n",
    "        tagged.append(rowdict)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_dict = {}\n",
    "\n",
    "for r in tagged:\n",
    "    if r['facility_id']:\n",
    "        site_dict[r['path_parts'][4]] = r['facility_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in tagged:\n",
    "    try:\n",
    "        f_id = site_dict[row['path_parts'][4]]\n",
    "        row['facility_id'] = f_id\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "untagged = []\n",
    "for row in tagged:\n",
    "    if row['facility_id'] is None:\n",
    "        untagged.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_find = set()\n",
    "for row in untagged:\n",
    "    to_find.add(row['path_parts'][4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hydrate = {\n",
    " 'Al Mlolah PHC': None,\n",
    " 'Al Salam FH': '117',\n",
    " 'AlMlolah PHC': None,\n",
    " 'AlSakhour Hospital': None,\n",
    " 'Albatraneh': None,\n",
    " 'Albatraneh PHC': None,\n",
    " 'Almlolah': None,\n",
    " 'Almlolah PHC': None,\n",
    " 'Alsalam Almaara': '115',\n",
    " 'Bab Al Hawa': '125',\n",
    " 'Bab Al Hawa DU': '124',\n",
    " 'Bab Alhwa Dialysis Unit': '124',\n",
    " 'Dec.xlsx': None,\n",
    " 'Dental 4.xlsx': None,\n",
    " 'Dental Rif Hama': None,\n",
    " 'Dental.xlsx': None,\n",
    " 'Ejaz Mobile Hospital': None,\n",
    " 'Ejaz PHC': None,\n",
    " 'Hama MC': '88',\n",
    " 'Hama Mc': '88',\n",
    " 'Hama Mobile Clinic': '88',\n",
    " 'Hama Mobile clinic': '88',\n",
    " 'Idleb FH': '127',\n",
    " 'Idlib FH': '127',\n",
    " 'Idlib field Hospital': '127',\n",
    " 'Idlib trama': '127',\n",
    " 'Ijaz': None,\n",
    " 'Ijaz MH': None,\n",
    " 'Ijaz Mobile Hospital': None,\n",
    " 'Ijaz PHC': None,\n",
    " 'Jabal Alzawia mobile clinicdental': '129',\n",
    " 'Jabal Alzawieh': '129',\n",
    " 'Jisr Al shgur': '130',\n",
    " 'Kafranbouteh PHC': '92',\n",
    " 'Kfrnbotheh': '92',\n",
    " 'M10 Trauma': '13',\n",
    " 'M3': '21',\n",
    " 'M3 PHC': '20',\n",
    " 'Mara Dialysis Center': None,\n",
    " 'Maree ObGyn': None,\n",
    " 'Mobile hospital': None,\n",
    " 'Nov.xlsx': None,\n",
    " 'Oct.xlsx': None,\n",
    " 'Osama Albarodi PHC': '94',\n",
    " 'Patient log 2, Al Rahma FH.xlsx': '274',\n",
    " 'Patient log, Al Rahma FH.xlsx': '274',\n",
    " 'Patient log, Al Rahma Fh.xlsx': '274',\n",
    " 'Patient log.xlsx': None,\n",
    " 'Physical Rehab.xlsx': None,\n",
    " 'Physical rehab.xlsx': None,\n",
    " 'Qastun PHC': '87',\n",
    " 'Rural Hama MC': '88'}\n",
    "\n",
    "site_dict = {**site_dict, **hydrate}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in tagged:\n",
    "    row['file_path'] = row['file_path'].replace(\"\\n\",'')\n",
    "    try:\n",
    "        f_id = site_dict[row['path_parts'][4]]\n",
    "        row['facility_id'] = f_id\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in tagged:\n",
    "    row['id'] = int(row['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "to_write = [header]\n",
    "\n",
    "from operator import itemgetter\n",
    "\n",
    "sorted_output = sorted(tagged, key=itemgetter('id')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in sorted_output:\n",
    "    r = [row[k] for k in header if '_parts' not in k]\n",
    "    to_write.append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('hydrated_file_facilities.csv','w',encoding='utf-8',newline='') as outfile:\n",
    "    writer = csv.writer(outfile)\n",
    "    for row in to_write:\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data was exported and joined back to the export of the files table. This file I'm importing contains the id from `files` and the facility_id from `facilities`. I'll use the values to update the `files` table. \n",
    "\n",
    "Note: If corrections are made to the exported table moving forward, the proper process will be to drop and recreate the `files` table with the updated data and would be best done in a separate notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'facility_id']\n"
     ]
    }
   ],
   "source": [
    "update_data = []\n",
    "with open('bind_files_to_facilities.csv','r',encoding='utf-8-sig') as csvfile:\n",
    "    csvreader = csv.reader(csvfile)\n",
    "    header = next(csvreader)\n",
    "    print(header)\n",
    "    for row in csvreader:\n",
    "        row_fixed = [int(e) for e in row if e != '']\n",
    "        rowdict = dict(zip(header,row_fixed))\n",
    "        if 'facility_id' in rowdict.keys():\n",
    "            update_data.append(rowdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tab_files = db['files']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for row in update_data:\n",
    "    tab_files.update(row,['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sams_data_phase10_template.sqlite'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Copy the database over as the template for the next file.\n",
    "# This Notebook did not include manual editing of the data.\n",
    "\n",
    "# Do not rerun this cell!\n",
    "shutil.copy2('sams_data_phase09.sqlite','sams_data_phase10_template.sqlite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
