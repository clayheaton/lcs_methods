{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the scrubbed data, this notebook consolidates the Arabic values and dispatches them to the Google Translate API to get an approximate English translation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Manipulate the file system\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Copy dictionaries\n",
    "import copy\n",
    "\n",
    "# Display errors in realtime\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# work with dates\n",
    "import datetime\n",
    "import arrow\n",
    "import time\n",
    "\n",
    "# For scrubbing PII\n",
    "import hashlib\n",
    "\n",
    "# Convert stored string representation of a list to a list\n",
    "import ast\n",
    "\n",
    "# Recurse through a directory tree and return file names with glob\n",
    "import glob\n",
    "\n",
    "# Decode and re-encode mangled Arabic file names\n",
    "import codecs\n",
    "\n",
    "# Connect to a SQLite database in a lazy manner.\n",
    "import sqlalchemy\n",
    "import dataset\n",
    "\n",
    "# Enables opening and reading of Excel files\n",
    "import openpyxl\n",
    "\n",
    "# Translating variables, sheet names, and workbook names from Arabic\n",
    "# This is NOT free to use.\n",
    "from google.cloud import translate\n",
    "\n",
    "# Set the environment variable for the Google Service Account\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = 'C:\\\\Users\\\\clay\\\\Documents\\\\fxb-lcs-2b24f4f8a73a.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#If there's an existing db for this sheet, delete it\n",
    "#so that we can copy from the template for a fresh start\n",
    "\n",
    "try:\n",
    "    os.remove(\"sams_data_phase06.sqlite\")\n",
    "    print(\"Removed template clone sams_data_phase06.sqlite\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    # Try to preserve a copy in case there is a problem and it has to be restored\n",
    "    shutil.copy2(\"sams_data_phase06_template.sqlite\",\"sams_data_phase06.sqlite\")\n",
    "    \n",
    "    print(\"Created database from template: sams_data_phase06.sqlite\")\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "db = dataset.connect(\"sqlite:///sams_data_phase06.sqlite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tab_raw = db['full_raw_scrubbed']\n",
    "tab_arabic = db['arabic_values']\n",
    "tab_vars = db['variables']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "column_names = db.query(\"SELECT DISTINCT(normalized) FROM variables;\")\n",
    "column_names = sorted([r['normalized'] for r in column_names])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We don't want to work with the values in the fields that have been hashed,\n",
    "# so remove them from the list of variables to query.\n",
    "fields = [\n",
    "    \"info_name\",\n",
    "    \"info_name_author\",\n",
    "    \"info_name_caregiver\",\n",
    "    \"info_name_facility\",\n",
    "    \"info_name_group\",\n",
    "    \"info_name_of_coach\",\n",
    "    \"info_name_processor\",\n",
    "    \"info_name_surgeon\",\n",
    "    \"info_phone_skype\",\n",
    "    \"date\",\n",
    "    \"date_first_exam\",\n",
    "    \"death_date\"\n",
    "]\n",
    "column_names = [e for e in column_names if e not in fields]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Iterate through the column names, get the distinct values, check\n",
    "# if they can be cast to floats. If  not, then translate them\n",
    "# The brackets are needed in the SQL query because some of the column\n",
    "# names are the same as SQL reserved words. The brackets tell the database\n",
    "# to look for a column with that name instead of interpreting it as\n",
    "# the reserved word. 'case' is an example here.\n",
    "\n",
    "tab_arabic.delete()\n",
    "\n",
    "for col in column_names:\n",
    "    col_values = db.query(\"\"\"\n",
    "        SELECT DISTINCT([\"\"\" + col + \"\"\"]) \n",
    "        FROM full_raw_scrubbed \n",
    "        WHERE [\"\"\" + col + \"\"\"] IS NOT NULL\n",
    "        AND [\"\"\" + col + \"\"\"] <> '.'\n",
    "        AND [\"\"\" + col + \"\"\"] <> '';\n",
    "        \"\"\")\n",
    "    col_values = [r[col] for r in col_values]\n",
    "\n",
    "    # Create a table of unique Arabic values\n",
    "    for v in col_values:\n",
    "        # Skip numbers\n",
    "        if v.replace(\",\",\".\").replace('.','',1).isdigit():\n",
    "            continue\n",
    "        else:\n",
    "            r = {\"arabic\":v,\"google_translate\":None,\"human_translate\":None,\"normalized\":None}\n",
    "            tab_arabic.upsert(r,['arabic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Arabic Character Ranges Regex\n",
    "# https://stackoverflow.com/questions/4446244/how-to-check-if-any-arabic-character-exists-in-the-string-javascript\n",
    "\n",
    "translate_client = translate.Client()\n",
    "target_lang = 'en'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "record_counter = widgets.HTML(value=\"Records: 0\",continuous_update=True)\n",
    "character_counter = widgets.HTML(value=\"Characters: 0\",continuous_update=True)\n",
    "error_counter = widgets.HTML(value=\"Errors: 0\",continuous_update=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "Done\n",
      "Record Count 0\n",
      "Character Count 0\n"
     ]
    }
   ],
   "source": [
    "character_count = 0\n",
    "record_count = 0\n",
    "error_count = 0\n",
    "\n",
    "for row in tab_arabic.find(google_translate=None):\n",
    "    if row['google_translate'] is None:\n",
    "        arabic_string = row['arabic']\n",
    "        arabic_string.replace(\"_\",\" \").replace(\"\\n\",\" \").replace(\"  \",\" \").replace(\"\\t\",\" \").strip()\n",
    "        try:\n",
    "            translation = translate_client.translate(arabic_string, target_language=target_lang)\n",
    "            rec = {\n",
    "                \"id\":row['id'],\n",
    "                \"google_translate\":translation['translatedText']\n",
    "            }\n",
    "\n",
    "            tab_arabic.update(rec,['id'])\n",
    "\n",
    "            character_count += len(row['arabic'])\n",
    "            character_counter.value = \"Characters: \" + str(character_count)\n",
    "            record_count += 1\n",
    "            record_counter.value = \"Records: \" + str(record_count)\n",
    "            \n",
    "        except:\n",
    "            error_count += 1\n",
    "            error_counter.value = \"Errors: \" + str(error_count)\n",
    "            time.sleep(10)\n",
    "            \n",
    "    else:\n",
    "        continue\n",
    "        \n",
    "print(\"--------------\\nDone\")\n",
    "print(\"Record Count\",record_count)\n",
    "print(\"Character Count\",character_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f31b89080694d8b81cf98d8425ab41d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "record_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d8cc3e9a01343239e76cf133ea94120"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "character_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7fa3d5f6f154c528db665c9f73f8adc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "error_counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "----\n",
    "\n",
    "There appears to be some PII in the data, so we're going to upsert all of the rows in the `arabic_values` table to track which columns the values appear in. That will allow us to obfuscate those columns before generating the English approximation table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the references\n",
    "\n",
    "arabic_reference = {}\n",
    "\n",
    "for row in tab_arabic.find():\n",
    "    arabic_reference[row['arabic']] = {'id':row['id'],'cols':set()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "353237"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(arabic_reference.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This takes a while to run\n",
    "\n",
    "for col in column_names:\n",
    "    col_values = db.query(\"\"\"\n",
    "        SELECT DISTINCT([\"\"\" + col + \"\"\"]) \n",
    "        FROM full_raw_scrubbed \n",
    "        WHERE [\"\"\" + col + \"\"\"] IS NOT NULL\n",
    "        AND [\"\"\" + col + \"\"\"] <> '.'\n",
    "        AND [\"\"\" + col + \"\"\"] <> '';\n",
    "        \"\"\")\n",
    "    col_values = [r[col] for r in col_values]\n",
    "    \n",
    "    # For each value in a given column, make sure our reference dict\n",
    "    # knows that the arabic_values row is referenced by that column\n",
    "    for arabic_value in col_values:\n",
    "        try:\n",
    "            arabic_reference[arabic_value]['cols'].add(col)\n",
    "        except:\n",
    "            # KeyError means we removed the value from arabic_values because\n",
    "            # it was not Arabic and did not require translation to English\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cols': {'analysis',\n",
       "  'col_1',\n",
       "  'col_2',\n",
       "  'col_3',\n",
       "  'notes',\n",
       "  'referral',\n",
       "  'referral_notes'},\n",
       " 'id': 5}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arabic_reference[list(arabic_reference.keys())[4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now take the data we have about which columns contain the relevant\n",
    "# values and upsert it into the arabic_values table\n",
    "\n",
    "for row_arabic in arabic_reference.keys():\n",
    "    row_data = arabic_reference[row_arabic]\n",
    "    data = {'id':row_data['id'],'appears_in':str(sorted(list(row_data['cols'])))}\n",
    "    tab_arabic.upsert(data,['id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem is that the variable named `N` was mapped to the normalized variable of `number` but should have been mapped to the variable `info_name`, so the records in those rows need to be fixed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "broken_records = db.query(\"\"\"\n",
    "    SELECT * FROM full_raw_scrubbed WHERE a_files_sheets_id IN (\n",
    "        SELECT DISTINCT(files_sheets_id) FROM files_sheets_vars WHERE var_id in (343)\n",
    "    );\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "broken_records = [r for r in broken_records]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27385"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(broken_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract the value from `number`, hash it, store it in `info_name`, then turn `number` into None/NULL\n",
    "# Do not save this value in a source code repository!\n",
    "salt = 'REDACTED'.encode()\n",
    "\n",
    "# h = hashlib.sha256()\n",
    "# h.update(rec[pii_field].encode())\n",
    "# h.update(salt)\n",
    "# rec[pii_field] = h.hexdigest()\n",
    "\n",
    "for rec in broken_records:\n",
    "    h = hashlib.sha256()\n",
    "    h.update(rec['number'].encode())\n",
    "    h.update(salt)\n",
    "    rec['info_name'] = h.hexdigest()\n",
    "    rec['number'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for rec in broken_records:\n",
    "    tab_raw.update(rec,['id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another scan of the `arabic_values` table shows that `col_null` mostly contains PII - probably patient names. This is a more complicated case because it's not apparent from the bulk context what each of these variables was intended to represent. \n",
    "\n",
    "Finding the problems:\n",
    "\n",
    "```\n",
    "SELECT full_raw_scrubbed.id,full_raw_scrubbed.a_files_sheets_id, full_raw_scrubbed.col_null, arabic_values.google_translate,full_raw_scrubbed.info_name\n",
    "FROM full_raw_scrubbed\n",
    "LEFT OUTER JOIN arabic_values ON full_raw_scrubbed.col_null = arabic_values.arabic\n",
    "WHERE full_raw_scrubbed.col_null IS NOT NULL\n",
    "ORDER BY full_raw_scrubbed.id ASC;\n",
    "```\n",
    "\n",
    "1. Find records where `col_null` IS NOT NULL and `info_name` IS NULL\n",
    "2. Delete matching `arabic_values` rows for values in `col_null`\n",
    "3. Hash `col_null` and move it to `info_name` for those records\n",
    "\n",
    "Note that these are `files_sheets_id` numbers 6986 and 7414 where `col_null` is `info_name`.\n",
    "\n",
    "\n",
    "This deletes the `arabic_values` entries:\n",
    "\n",
    "```\n",
    "DELETE FROM arabic_values WHERE arabic IN (\n",
    "    SELECT DISTINCT(col_null) FROM full_raw_scrubbed\n",
    "    WHERE col_null IS NOT NULL \n",
    "    AND info_name IS NULL\n",
    ");\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "753"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "broken_records = db.query(\"\"\"\n",
    "    SELECT * FROM full_raw_scrubbed\n",
    "    WHERE col_null IS NOT NULL \n",
    "    AND info_name IS NULL;\n",
    "\"\"\")\n",
    "broken_records = [r for r in broken_records]\n",
    "len(broken_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for rec in broken_records:\n",
    "    h = hashlib.sha256()\n",
    "    h.update(rec['col_null'].encode())\n",
    "    h.update(salt)\n",
    "    rec['info_name'] = h.hexdigest()\n",
    "    rec['col_null'] = None\n",
    "    \n",
    "for rec in broken_records:\n",
    "    tab_raw.update(rec,['id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "It appears that most PII is cleaned at this point in time, so create the approximation English table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tab_full_english = db['full_raw_english']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a reference lookup\n",
    "arabic_reference = {}\n",
    "\n",
    "for row in tab_arabic.find():\n",
    "    arabic_reference[row['arabic']] = row['google_translate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "buffer = []\n",
    "buffer_max_size = 10000\n",
    "\n",
    "for row in tab_raw.find():\n",
    "    new_row = {}\n",
    "    for key in row.keys():\n",
    "        row_value = row[key]\n",
    "        try:\n",
    "            new_row[key] = arabic_reference[row_value]\n",
    "        except:\n",
    "            new_row[key] = row_value\n",
    "    buffer.append(new_row)\n",
    "    \n",
    "    if len(buffer) > buffer_max_size:\n",
    "        tab_full_english.insert_many(buffer)\n",
    "        buffer.clear()\n",
    "        \n",
    "# Clean up dangling rows\n",
    "tab_full_english.insert_many(buffer)\n",
    "buffer.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this is (literally) an expensive notebook to run. The Google Translate costs are probably in the order of $300 or so. Probably best not to run it again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sams_data_phase07_template.sqlite'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Copy the database over as the template for the next file.\n",
    "# This Notebook did not include manual editing of the data.\n",
    "\n",
    "# Do not rerun this cell!\n",
    "# shutil.copy2('sams_data_phase06.sqlite','sams_data_phase07_template.sqlite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
